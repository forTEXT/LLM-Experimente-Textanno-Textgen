# Tests für die Generierung des Textteils über das Design der Experimente

## **ChatGPT**
### Experiment 1 - Abschnitt zu LLM-Anpassungen

Prompt:
Schreibe einen Abschnitt eines wissenschaftlichen Artikels über den Einsatz von LLMs für literaturwissenschaftliche Textanalysen. Es geht in diesem Abschnitt darum, zuerst die Funktionalität von LLMs für ein nicht-informatisches Publikum zu erläutern. Anschließend sollen die Möglichkeiten, LLMs anzupassen, beschrieben werden. Diese Möglichkeiten sind a) das Trainieren eines Basismodells bzw. Foundation Models, b) Transfer Learning, c) Finetuning, d) Retrieval Augmented Generation und e) Prompting (Prompting in Bezug auf gängige Möglichkeiten des Prompt Engineerings, dann die speziellen Möglichkeiten des Zero-Shot-, One-Shot-, und Few-Shot-Promptings). Jede dieser Möglichkeiten soll kurz erklärt werden. Danach sollen die Herausforderungen in der Umsetzung beschreiben werden in Bezug auf die benötigten Daten bzw. den Input, die benötigten Rechenressourcen und das nötige technische Know How. Nutze sowohl für die Erläuterung der Funktionalität von LLMs als auch für die Vorstellung der verschiedenen Anpassungsmöglichkeiten einschlägige Literaturverweise, sofern es diese bereits gibt.

Prompt und Output: https://chatgpt.com/share/67128bb8-4068-8004-89ac-899c510a1563 (18.10.2024, ChatGPT-4o)

### Experiment 2 (Mit Tippfehlern)
Prompt:
Schreibe einen Abschnitt eines wissenschaftlichen Artikels über den Einsatz von LLMs für literaturwissenschaftliche Textanalysen. In diesem Abschnitt geht es darum, die Experimente zu beschreiben, die durchgeführt wurden. Nutze dafür, wo möglich, geeignete Verweise auf Forschungsliteratur und schreibe die nachfolgend beschriebenen drei Unterabschnitte. Beschränke Dich auf die drei Unterabschnitte, schreibe keine Einleitung und keine Zusammenfassung.
Im ersten Unterabschnitt soll der genutzte Gegenstand beschrieben werden. Es geht um Analysen der Chronologie in Prosatexten, wie sie im heureCLÉA Projekt umgesetzt wurden. Die für die Experimente zentrale Frage ist entsprechend, ob das Modell im allgemeinen Ordnungsphänomene oder die drei anachronischen Ordnungsphänomene Analepse (Vorgriff), Prolepse (Rückgriff) und Simullepse (Parallelgeschehen) sowie als viertes Phänomen Achronien, also Textabschnitte, deren zeitliche Position in der Chronologie der Erzählung nicht bestimmbar ist, erkennt.
Im zweiten Unterabschnitt sollen zuerst die Funktionalitäten von LLMs für ein Publikum erläutert werden, dass über wenig oder keine Informatikkenntnisse verfügt. Anschließend sollen die Möglichkeiten, LLMs für eine bestimmte Aufgabe zu nutzen, beschrieben werden. Diese Möglichkeiten sind a) das Trainieren eines Basismodells   bzw. Foundation Models und die darauf aufbauenden Anpassungen durch b) Transfer Learning, c) Finetuning, d) Retrieval Augmented Generation und e) Prompting (Prompting in Bezug auf gängige Möglichkeiten des Prompt Engineerings, dann die speziellen Möglichkeiten des Zero-Shot-, One-Shot-, und Few-Shot-Promptings). Jede dieser Möglichkeiten soll kurz erklärt werden. Danach sollen die Herausforderungen in der Umsetzung beschreiben werden in Bezug auf die benötigten Daten bzw. den Input, die benötigten Rechenressourcen und das nötige technische Knowhow.
Nutze  sowohl für die Erläuterung der Funktionalitäten von LLMs als auch für die Vorstellung der verschiedenen Anpassungsmöglichkeiten einschlägige Literaturverweise, sofern es diese bereits gibt.
Im dritten Abschnitt soll das Experimentsetting beschrieben werden.
Das übergeordnete Ziel der Experimente ist, Annotationen in einem bestimmten Format mit einem LLM zu generieren. Das Experiment wird mit dem Tool LM Studio durchgeführt, welches es erlaubt, verschiedene LLMs auf einem lokalen Server auf dem eigenen Rechner laufen zu lassen. Wir nutzen Llama 3.1, genauer die Version “Meta-Llama-3.1-8B-Instruct-IQ4_XS.gguf”, da es ein offenes Modell ist und zudem mit am besten abschneidet. Es wird eine Reihe von Experimenten mit verschiedenen Prompt-Anweisungen durchgeführt, um die beste Promptstrategie bzw. den besten Prompt zu finden, der zum gewünschten Ergebnis (Annotationen in einem bestimmten Ausgabeformat) führt. Dafür wird das LLM zunächst auf einen einzelnen Text und einen Teil der Guidelines getestet. Explorativ wird Llama geprompted, bis es einen Output generiert, der dem gewünschten Ausgabeformat entspricht und möglichst korrekte Annotationen in geeignetem Umfang generiert. Dieser Prompt soll dann für weitere Experimente genutzt.  
Neben der Anweisung einen übergebenen Text zu annotieren, übergeben wir dem LLM als Input 1) den zu annotierenden Text im TXT-Format, 2) den Abschnitt zu Ordnung („order“) aus der Annotationsrichtlinie im Markdown-Format sowie 3) manuelle, im heureCLÉA-Projekt angefertigte, Annotationen im gewünschten Ausgabeformat als Annotationsbeispiele. In der Annotationsrichtlinie wurden Fußnoten, Referenzen auf Abbildungen und eine Überblickstabelle entfernt. Die Richtlinie und der zu annotierende Text (“Auch ich war in Arkadien” von Joseph von Eichendorff, 1834) werden dem System auf Deutsch übergeben. 

Prompt + Output: https://chatgpt.com/share/6729ed0d-ee5c-8004-8257-a0c456bd8a24 (18.10.2024, ChatGPT-4o)

### Experiment 3

Prompt: 
Schreibe einen Abschnitt eines wissenschaftlichen Artikels über den Einsatz von LLMs für literaturwissenschaftliche Textanalysen. In diesem Abschnitt geht es darum, die Experimente zu beschreiben, die durchgeführt wurden. Nutze dafür, wo möglich, geeignete Verweise auf Forschungsliteratur und schreibe die nachfolgend beschriebenen drei Unterabschnitte. Beschränke Dich auf die drei Unterabschnitte, schreibe keine Einleitung und keine Zusammenfassung.
Im ersten Unterabschnitt soll der genutzte Gegenstand beschrieben werden. Es geht um Analysen der Chronologie in Prosatexten, wie sie im heureCLÉA Projekt umgesetzt wurden. Die für die Experimente zentrale Frage ist entsprechend, ob das Modell im allgemeinen Ordnungsphänomene oder die drei anachronischen Ordnungsphänomene Analepse (Vorgriff), Prolepse (Rückgriff) und Simullepse (Parallelgeschehen) sowie als viertes Phänomen Achronien, also Textabschnitte, deren zeitliche Position in der Chronologie der Erzählung nicht bestimmbar ist, erkennt.
Im zweiten Unterabschnitt sollen zuerst die Funktionalitäten von LLMs für ein Publikum erläutert werden, das über wenig oder keine Informatikkenntnisse verfügt. Anschließend sollen die Möglichkeiten, LLMs für eine bestimmte Aufgabe zu nutzen, beschrieben werden. Diese Möglichkeiten sind a) das Trainieren eines Basismodells bzw. Foundation Models und die darauf aufbauenden Anpassungen durch b) Transfer Learning, c) Finetuning, d) Retrieval Augmented Generation und e) Prompting (Prompting in Bezug auf gängige Möglichkeiten des Prompt Engineerings, dann die speziellen Möglichkeiten des Zero-Shot-, One-Shot-, und Few-Shot-Promptings). Jede dieser Möglichkeiten soll kurz erklärt werden. Danach sollen die Herausforderungen in der Umsetzung beschreiben werden in Bezug auf die benötigten Daten bzw. den Input, die benötigten Rechenressourcen und das nötige technische Knowhow. Nutze sowohl für die Erläuterung der Funktionalitäten von LLMs als auch für die Vorstellung der verschiedenen Anpassungsmöglichkeiten einschlägige Literaturverweise, sofern es diese bereits gibt.
Im dritten Unterabschnitt soll das Experimentsetting beschrieben werden. Das übergeordnete Ziel der Experimente ist, Annotationen in einem bestimmten Format mit einem LLM zu generieren. Das Experiment wird mit dem Tool LM Studio durchgeführt, welches es erlaubt, verschiedene LLMs auf einem lokalen Server auf dem eigenen Rechner laufen zu lassen. Wir nutzen Llama 3.1, genauer die Version “Meta-Llama-3.1-8B-Instruct-IQ4_XS.gguf”, da es ein offenes Modell ist und zudem mit am besten abschneidet. Es wird eine Reihe von Experimenten mit verschiedenen Prompt-Anweisungen durchgeführt, um die beste Promptstrategie bzw. den besten Prompt zu finden, der zum gewünschten Ergebnis (Annotationen in einem bestimmten Ausgabeformat) führt. Dafür wird das LLM zunächst auf einen einzelnen Text und einen Teil der Guidelines getestet. Explorativ wird Llama geprompted, bis es einen Output generiert, der dem gewünschten Ausgabeformat entspricht und möglichst korrekte Annotationen in geeignetem Umfang generiert. Dieser Prompt soll dann für weitere Experimente genutzt. Neben der Anweisung einen übergebenen Text zu annotieren, übergeben wir dem LLM als Input 1) den zu annotierenden Text im TXT-Format, 2) den Abschnitt zu Ordnung („order“) aus der Annotationsrichtlinie im Markdown-Format sowie 3) manuelle, im heureCLÉA-Projekt angefertigte, Annotationen im gewünschten Ausgabeformat als Annotationsbeispiele. In der Annotationsrichtlinie wurden Fußnoten, Referenzen auf Abbildungen und eine Überblickstabelle entfernt. Die Richtlinie und der zu annotierende Text (“Auch ich war in Arkadien” von Joseph von Eichendorff, 1834) werden dem System auf Deutsch übergeben.


Prompt + Output: https://chatgpt.com/share/672a4dc1-7614-8004-b26f-5bd7141c8105 (04.11.2024, ChatGPT-4o)